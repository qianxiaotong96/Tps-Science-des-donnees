{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;background-color:#336699;color:white;\">TP3\n",
    "Introduction à la classification</h1>\n",
    "<h3 style=\"color:#8080C0\">A. Plus Proche Voisin</h3>\n",
    "<h4>1. Créez une fonction PPV(X,Y) qui prend en entrée des données X et des étiquettes Y et qui renvoie une étiquette, pour chaque donnée, prédite à partir du plus proche voisin de cette donnée. Ici on prend chaque donnée, une par une, comme donnée de test et on considère toutes les autres comme données d’apprentissage. Cela nous permet de tester la puissance de notre algorithme selon une méthode de validation par validation croisée (cross validation) de type “leave one out”.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: QIAN Xiaotong\n",
    "@author: BIAN Yiping\n",
    "\"\"\"\n",
    "\n",
    "from sklearn import * \n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from scipy.stats import mode\n",
    "\n",
    "'''\n",
    "x -> les donnees\n",
    "y -> class\n",
    "renvoie la class du voisin qui est plus proche de cette donnees\n",
    "'''\n",
    "\n",
    "# print(metrics.pairwise.euclidean_distances(iris.data))  \n",
    "# permet de calculer la distance de tous les voisin de chaque donnee\n",
    "# np.argsort(metrics.pairwise.euclidean_distances(x))\n",
    "# trier le tab de distance dans l'ordre croissant par indice.\n",
    "# print(np.argsort(metrics.pairwise.euclidean_distances(iris.data))[:,1])\n",
    "# renvoie la deuxième indice de la tab triée\n",
    "# iris.target[np.argsort(metrics.pairwise.euclidean_distances(x))[:,1]]\n",
    "# renvoie les class de chaque donnees de la tab qui contient la deuxième indice de la tab triée\n",
    "def ppv(x,y):\n",
    "    z = y[np.argsort(metrics.pairwise.euclidean_distances(x))[:,1]]\n",
    "    return z "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2. La fonction PPV calcule une étiquette prédite pour chaque donnée. Modifiez la fonction pour calculer et renvoyer l’erreur de prédiction : c’est à dire le pourcentage d’étiquettes mal prédites.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppv_err(x,y):\n",
    "    res = np.zeros(len(y))\n",
    "    z = y[np.argsort(metrics.pairwise.euclidean_distances(x))[:,1]]\n",
    "    res = len(np.nonzero(abs(y-z)))/len(y)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>3. Testez sur les données Iris.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "0.006666666666666667\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "z = ppv(iris.data,iris.target)\n",
    "\n",
    "print(z)\n",
    "\n",
    "err = ppv_err(iris.data,iris.target)\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>4. Testez la fonction des K Plus Proches Voisins de sklearn (avec ici K = 1). Les\n",
    "résultats sont-ils différents? Testez avec d’autres valeurs de K.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "neigh_1 = KNeighborsClassifier(n_neighbors=1)  \n",
    "neigh_1.fit(iris.data, iris.target)\n",
    "print(neigh_1.predict(iris.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "neigh_2 = KNeighborsClassifier(n_neighbors=2)  \n",
    "neigh_2.fit(iris.data, iris.target)\n",
    "print(neigh_2.predict(iris.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "neigh_3 = KNeighborsClassifier(n_neighbors=3)  \n",
    "neigh_3.fit(iris.data, iris.target)\n",
    "print(neigh_3.predict(iris.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>5. BONUS : Modifiez la fonction PPV pour qu’elle prenne en entrée un nombre K de voisins (au lieu de 1). La classe prédite sera alors la classe majoritaire parmi les K voisins.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1.\n",
      " 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2.]\n",
      "verification:\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def ppv_k(x,y,k):\n",
    "    data = np.argsort(metrics.pairwise.euclidean_distances(x))\n",
    "    tab = np.zeros((k,len(data)))\n",
    "    for i in range(k):\n",
    "        for j in range(len(data)):\n",
    "            tab[i][j] = y[data[:,i+1][j]]\n",
    "    return mode(tab)[0][0]\n",
    "\n",
    "print(ppv_k(iris.data,iris.target,2))\n",
    "print(\"verification:\")\n",
    "print(ppv_k(iris.data,iris.target,2).all() == neigh_2.predict(iris.data).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#8080C0\">A. Classifieur Bayesien Naïf</h3>\n",
    "<h4>1. Créez une fonction CBN(X,Y) qui prend en entrée des données X et des étiquettes Y et qui renvoie une étiquette, pour chaque donnée, prédite à partir de la classe la plus probable selon l’équation (1). Ici encore, on prend chaque donnée, une par une, comme donnée de test et on considère toutes les données comme données d’apprentissage. Il est conseillé de calculer d’abord les barycentres et les probabilités à priori P(ωk) pour chaque classe, puis de calculer les probabilités conditionnelles P(xi/ωk) pour chaque classe et chaque variable.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2.,\n",
       "       1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2.,\n",
       "       2., 2., 2., 2., 1., 2., 2., 2., 2., 2., 2., 1., 2., 2., 2., 2., 2.,\n",
       "       1., 2., 1., 2., 2., 2., 2., 1., 1., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cbn(x,y):\n",
    "    ############ \n",
    "    # calculer le barycentre    \n",
    "    dic = {}\n",
    "    barycentre = np.zeros((len(np.unique(y)),x.shape[1]))\n",
    "\n",
    "    for i in range(len(np.unique(y))):\n",
    "        dic[i] = np.zeros((len(np.where(y==i)[0]),x.shape[1]))\n",
    "        j=0\n",
    "        for k in np.where(y==i)[0]:\n",
    "            dic[i][j] = x[k]\n",
    "            j=j+1\n",
    "        barycentre[i] = np.mean(dic[i],axis = 0)\n",
    "    ############\n",
    "    # calculer le probabilite pwk\n",
    "    pw = np.zeros(len(np.unique(y)))\n",
    "    for i in range(len(np.unique(y))):\n",
    "        pw[i] = sum(y == i)/y.size\n",
    "    ###########\n",
    "    #p conditionel p(xi|wk)\n",
    "    p_cond = np.zeros((len(x),len(np.unique(y))))\n",
    "    for k in range(len(np.unique(y))):\n",
    "        for i in range(len(x)):\n",
    "            sum_xb = 0\n",
    "            dxk = 0\n",
    "            dxk = metrics.pairwise.euclidean_distances([x[i],barycentre[k]])[0][1] #Dxk\n",
    "            for j in range(len(np.unique(y))):\n",
    "                sum_xb = sum_xb + metrics.pairwise.euclidean_distances([x[i],barycentre[j]])[0][1] #Dxk\n",
    "            p_cond[i][k] = 1-(dxk/sum_xb)\n",
    "    ##########\n",
    "    #calculer la distribution du class\n",
    "    class_x = np.zeros(len(x))\n",
    "    p_final = np.zeros(len(np.unique(y)))\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(np.unique(y))):\n",
    "                p_final[j] = p_cond[i][j]*pw[j]\n",
    "        class_x[i] = np.argmax(p_final)\n",
    "    \n",
    "    return class_x\n",
    "cbn(iris.data,iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "2. La fonction CBN calcule une étiquette prédite pour chaque donnée. Modifiez la fonction pour calculer et renvoyer l’erreur de prédiction : c’est à dire le pourcentage d’étiquettes mal prédites. Testez sur les données Iris.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07333333333333333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cbn_erreur(x,y):\n",
    "    ############ \n",
    "    # calculer le barycentre    \n",
    "    dic = {}\n",
    "    barycentre = np.zeros((len(np.unique(y)),x.shape[1]))\n",
    "\n",
    "    for i in range(len(np.unique(y))):\n",
    "        dic[i] = np.zeros((len(np.where(y==i)[0]),x.shape[1]))\n",
    "        j=0\n",
    "        for k in np.where(y==i)[0]:\n",
    "            dic[i][j] = x[k]\n",
    "            j=j+1\n",
    "        barycentre[i] = np.mean(dic[i],axis = 0)\n",
    "    ############\n",
    "    # calculer le probabilite pwk\n",
    "    pw = np.zeros(len(np.unique(y)))\n",
    "    for i in range(len(np.unique(y))):\n",
    "        pw[i] = sum(y == i)/y.size\n",
    "    ###########\n",
    "    #p conditionel p(xi|wk)\n",
    "    p_cond = np.zeros((len(x),len(np.unique(y))))\n",
    "    for k in range(len(np.unique(y))):\n",
    "        for i in range(len(x)):\n",
    "            sum_xb = 0\n",
    "            dxk = 0\n",
    "            dxk = metrics.pairwise.euclidean_distances([x[i],barycentre[k]])[0][1] #Dxk\n",
    "            for j in range(len(np.unique(y))):\n",
    "                sum_xb = sum_xb + metrics.pairwise.euclidean_distances([x[i],barycentre[j]])[0][1] #Dxk\n",
    "            p_cond[i][k] = 1-(dxk/sum_xb)\n",
    "    ##########\n",
    "    #calculer la distribution du class\n",
    "    class_x = np.zeros(len(x))\n",
    "    p_final = np.zeros(len(np.unique(y)))\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(np.unique(y))):\n",
    "                p_final[j] = p_cond[i][j]*pw[j]\n",
    "        class_x[i] = np.argmax(p_final)\n",
    "    \n",
    "    class_x = (class_x == y) \n",
    "    nb = np.sum(class_x == 0)\n",
    "    return nb/len(y)\n",
    "cbn_erreur(iris.data,iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>3. Testez la fonction du Classifieur Bayesien Naïf inclut dans sklearn. Cette fonc- tion utilise une distribution Gaussienne au lieu des distances aux barycentres. Les résultats sont-ils différents ?</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((clf.predict(iris.data) == cbn(iris.data,iris.target)) == 0)/len(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((clf.predict(iris.data) == iris.target) == 0)/len(iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:green\">Ils ont 6% de différence selon le résultat obtenu, mais l'erreur de prédiction de la méthode \"GaussianNB\" (0.04) est moins que la fonction CBN (0.07333333333333333)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''fait par qn d'aure '''\n",
    "def CBN(X, Y):\n",
    "    # liste des moyennes (barycentre) de la classe\n",
    "    moy = [np.mean(X[(Y==0)], axis=0), np.mean(X[(Y==1)], axis=0), np.mean(X[(Y==2)], axis=0)]\n",
    "    # on convertit cette liste de moyenne en tableau numpy plus facile à manipuler\n",
    "    moy=np.asarray(moy)\n",
    "\n",
    " \n",
    "\n",
    "    # distance euclidienne entre une donnée X et le barycentre (moyenne) de la classe\n",
    "    dxk = metrics.pairwise.euclidean_distances (X, moy)\n",
    "    \n",
    "    # somme des distances entre la donnée X et chaque barycentre de chaque classe\n",
    "    dxb=np.sum(dxk, axis=1)\n",
    "    pxk = np.zeros(450,dtype=float).reshape((150, 3))\n",
    "    for i in range (0,len(dxb)):\n",
    "        for j in range (0, 3):\n",
    "            # probabilité qu'une donnée X ait la valeur Xi pour la variable i connaissant sa classe\n",
    "            pxk[i][j]=1-(dxk[i][j]/dxb[i]) \n",
    "    \n",
    "    # propabilité d'appartenance à chaque classe\n",
    "    Ybay=np.argmax(pxk, axis=1)\n",
    "    return Ybay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CBN(iris.data,iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
